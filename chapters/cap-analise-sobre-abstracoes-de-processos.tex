\chapter{Analise Sobre Abstrações de Processos}
\label{cap:analise-sobre-abstracoes-de-processos}

No Capítulo \ref{cap:trabalhos-analisados} introduzimos os principais trabalhos
que orbitam sobre as novas abstrações de processos para que nesse capítulo seja
feito uma reflexão sobre as principais características de tais pesquisas. No
decorrer deste o capítulo realizamos diversas analises sobre o estado da arte
dos diferentes trabalhos e apresentamos um modelo teórico que visa apresentar
uma perspectiva para a nova geração de abstrações de processos.  Esse capítulo
responde as seguintes perguntas de pesquisa:

\begin{quote}
 \item \textit{RQ1:.} "Quais são as características desejáveis para a próxima geração de abstrações de processos?"
 \item \textit{RQ2:.} "Quais são os principais desafios em se implementar a próxima geração de abstrações de processos?"
\end{quote}

Um dos diferenciais desse trabalho, consiste em considerar o uso de novas
extensões nas abstrações de processos levando em consideração SOs de uso
cotidiano, em especial o GNU/Linux. Esse critério é importante, pois
acreditamos que se tais abstrações chegarem até os SOs de ampla utilização,
novos ramos de pesquisa podem surgiram.

\section{Potenciais e Dificuldades Para Adotar Novas Abstrações de Processos}
\label{sec:potenciais}

Pesquisas em SO buscam avançar o estado da arte, contudo, SOs
usados em produção e em projetos de pesquisa possuem diferentes restrições. Se
uma nova proposta feita pela academia tem por objetivo ser utilizada em
aplicações que estão no estado da prática, essas devem considerar questões
referentes a compatibilidade, melhor uso do hardware disponível, confiabilidade
e ser genérico o bastante para ser utilizado por múltiplas linguagens de
programação.

Os SOs usados em produção demandam rigorosa validação para manter o sistema
estável em uma variedade de configurações, como prevenir acesso ilegal a
memória, impossibilitar violação de API, evitar consumo excessivo de recursos e
impedir erros de sincronização ou \textit{locking}. Essas características tem
que ser garantidas pelo SO \citep{mondrix}, como pode-se esperar, tais
restrições são complicadas de serem atendidas por propostas de pesquisas uma
vez que essas normalmente concentram-se em um único problema sem considerar
outros impactos.  Por esses motivos, para que um novo componente sugerido por
meio da pesquisa chegue aos SOs atuais, é importante garantir que as aplicações
que já existem não sofram impactos negativos em termos de desempenho e de uso.

Outra perspectiva que deve ser considerada é o contínuo desenvolvimento de novos
recursos de hardware, por exemplo, é comum observar componentes que
são especializados em um nicho e que ao longo do tempo chegam ao usuário
final tornando-se comum. Um caso simples que ilustra tal evolução é o
uso de hardware especializado para virtualização, uma vez que esses existiam
apenas para servidores e hoje estão disponíveis para a maioria dos usuários
comuns. Tais recursos representam um novo leque de opções não exploradas,
inclusive para trazer melhorias para as atuais abstrações de processos.
Entretanto, qualquer tentativa de incorporar os novos recursos de hardware para
a abstração de processos deve levar em consideração que alguns usuários podem
não ter tal recurso disponível. Por essa razão qualquer mudança nos processos
que adicionem suporte a novos recursos de hardware devem levar em consideração
todo tipo de caso. De modo inverso, propostas para melhorar uma abstração de
processos podem sugerir mudanças no hardware sendo útil para avançar os
estado da arte dos chips modernos. Claro que a evolução do hardware deve ser
cuidadosa para evitar quebrar a compatibilidade binária com aplicações legadas.
Infelizmente, é preciso ter em mente que alteração de hardware e suas
limitações faz com propostas que dependem de tal evolução sejam difíceis de
serem adotadas e fazem com que a ampla adoção de uma determinada melhoria seja
impraticável.

Algumas das novas abstrações de processos propostas por alguns pesquisadores
tem enorme dependência com outras tecnologias experimentais. Se por um lado
isso traz vantagens para as tecnologias em desenvolvimento, por outro reduz a
chance de uma nova abstração de processos ser adotada por um SO de produção
devido a dependência em tecnologias instáveis.

%TODO
Encontrar um bom balanceamento entre academia e a indústria de forma a levar
benefícios para os usuários não é uma tarefa trivial. Nesse sentido, novas
propostas de mudanças na abstração de processos deve considerar as limitações
citadas nessa seção para que possam atender aos requisitos de qualidade
exigidas pelos SOs de uso cotidiano. Infelizmente, afirmar se uma proposta da
academia pode ser adotada ou não pela indústria é uma tarefa impossível de ser
determinar dado a enorme quantidade de variáveis envolvidas em tal análise.
Mesmo assim, para posicionar o leitor em termos do estado da arte e da prática, nós
buscamos estabelecer um "potencial de adoção" de uma nova proposta. Com base
nos critérios apresentados nessa seção buscamos definir um conjunto de
variáveis que auxilie na definição das chances de uma pesquisa ser adotada pela
indústria, segue:

\begin{enumerate}
  \item
\textbf{Dependência Técnica}: essa variável indica se o trabalho é construído
levando-se em consideração outras tecnologias não estabilizadas. Consideramos
tal aspecto um problema para a adoção da nova técnica por parte de um SO de uso
cotidiano.

  \item
\textbf{Dependência de Compatibilidade}: refere-se as propostas que exigem
alterações na semântica das aplicações em espaço de usuário para que essas
possam tirar proveito de alguma melhoria. Para esses casos desconsideramos
propostas que simplesmente chamam uma única função que não alteram em nada na
semântica.

  \item
\textbf{Dependência de Compilador}: propostas que dependem de alterações no
compilador. Nesses casos, consideramos que a adoção torna-se um pouco mais
complicado uma vez que dois projetos precisam ser alterados.

  \item
\textbf{Implementação Pesada}: consideramos as implementações pesadas mais
complicadas já que necessitam que mudanças no núcleo sejam feitas, isso pode
dificultar a adoção.

  \item
\textbf{Implementação Independente}: essa refere-se a propostas de novas
implementações, claramente essa é de difícil adoção.

  \item
\textbf{Hardware Novo}: essa variável indica que a proposta depende de um
hardware novo que só existe em algum contexto específico ou mesmo que ainda não
foi implementado.

  \item
\textbf{Característica Específica de Hardware}: refere-se a propostas que
propõem a utilização de algum hardware bem consolidado para algum outro
proposito diferente do originalmente proposto.

\end{enumerate}

A Tabela \ref{tab:adocao} tenta apresentar o potencial de adoção de cada uma
das propostas citadas no Capítulo \ref{cap:trabalhos-analisados} de acordo com
as variáveis discutidas nessa seção. Na tabela, temos uma marcação indicada
pelo simbolo \ding{52} que significa que uma determinada proposta possui a
limitação indicada na coluna. Se a proposta não contém tal restrição, então ela
é marcada com o simbolo \ding{54}. Por uma questão de simplicidade, para
definir o potencial de adoção atribuímos um para cada \ding{54} e zero para
\ding{52}. Por fim, toda vez que a opção "Hardware Novo" é marcada nós
consideramos que a proposta contém todos os empecilhos para a adoção; para as
variáveis referentes a implementação, consideramos que quando uma proposta
parte de uma implementação independente ela também é considerada pesada.

\input{tables/potencial_adocao}

\section{Extraído Conceitos Derivados das Pesquisas em Abstrações de Processos}

Todas as pesquisas apresentadas no Capítulo \ref{cap:trabalhos-analisados}
representam o estado da arte no que se refere as abstrações de processos,
infelizmente nenhuma delas encontra-se no código principal de qualquer SO de
uso cotidiano. Parte desse problema vem dos fatos apresentados na Seção
\ref{sec:potenciais}, contudo outros aspectos que contribuem para que tais
propostas não estejam presentes nos SO modernos vem da falta de unificação e
sistematização de tais ideias. Ao analisar cada uma das propostas, notamos que
todas elas propõem direta ou indiretamente algum nível de desacoplamento entre
os elementos presentes no SO. Tal observação nasce da abordagem radical tomada
pelos criadores do Exokernel, que levaram o nível de desacoplamento do SO ao
extremo. Apesar do Exokernel ser um sistema difícil de ser adotado em termos
práticos, ele nós alerta sobre as vantagens em se reduzir as dependências
entre os elementos do SO e as possibilidades que isso pode levar ao espaço de
usuário. Nesse sentido revisitamos de forma breve alguns dos trabalhos
apresentados no Capítulo \ref{cap:trabalhos-analisados} sob a ótica do
desacoplamento e seus potenciais benefícios.

O projeto Dune traz uma nova perspectiva de uso dos recursos de virtualização
disponibilizados pelas CPUs modernas, consequentemente esse traz dois
benefícios diretos: otimização e flexibilidade. Ao utilizar os recursos de
virtualização para acelerar certas tarefas, o Dune promoveu avanços em um setor
difícil de ser otimizado. Além disto, tais melhorias facilitam certas
implementações no espaço de usuário, pois removem a necessidade de códigos com
técnicas avançadas que visam trazer melhorias de desempenho; em outras
palavras, a proposta do Dune pode melhorar a legibilidade de alguns códigos.
Todos esses avanços são factíveis graças ao \textbf{desacoplamento da
virtualização}, que por sua vez possibilita entregar melhor desempenho no
espaço de usuário de maneira relativamente simples do ponto de vista da
aplicação e também entregam benefícios de segurança.

Já o projeto Nooks se distância um pouco da abstração de processos uma vez que
ele busca tornar o núcleo do SO mais resiliente. Contudo, ao criar mecanismos
que reagem de forma a reduzir as chances do sistema quebrar, o mesmo apresenta
uma proposta de \textbf{desacoplamento dos recursos} de forma a fornecer
mecanismos para que os processos possam se recuperar ou tomar ações em casos de
falhas.  Adicionalmente, tal técnica também cria um interessante mecanismo de
comunicação entre as extensões do Kernel e os seus drivers que permite o SO se
proteger de problemas que aconteceu com um código que foi acoplado ao seu
núcleo.

De forma mais direta e sistemática o \textit{Resource Container} sugere o
controle fino do gerenciamento de recursos e consequentemente o desacoplamento
de tal elemento. De certa maneira, tal proposta já pode ser vista incorporado
nós SOs atuais, na forma dos containers no Linux, mais especificamente, como o
\textit{cgroups}. A principal contribuição do trabalho, vem da sua capacidade
de permitir que a própria aplicação tome conta da sua execução.  Vale observar
que ainda que parte das ideias apresentada por essa pesquisa estejam presentes
em alguns SOs, as implementações ainda são relativamente reduzidas em termos do
escopo apresentado na pesquisa.

Uma abordagem alternativa que visa atender uma nova geração de computadores com
memórias não voláteis e que são da ordem dos petabytes é o SpaceJMP/MVAS.  Os
autores sugerem \textbf{desacoplar o VAS dos processos} e permitir que esses
tenham múltiplas VAS e de forma reativa, a aplicação torne-se capaz de mudar o
VAS atual. Essa abordagem faz com que um processo consiga acessar regiões muito
maiores do que aquelas garantidas pelo tamanho de uma VAS. Indiretamente
desacoplar uma VAS adiciona a possibilidade de criar processos persistentes,
isto é, que vivem mesmo após o boot ou mesmo após um problema. Desacoplar a VAS
pode trazer benefícios para aplicações de \textit{checkpoints}, melhorar o
gerenciamento de bibliotecas, elevar o nível de isolamento e compartilhamento.

O Light-weight Context (lwC) indiretamente propõe o total
\textbf{desacoplamento do PC}; vale observar que os autores explicitam outros
desacoplamentos, contudo, para esse trabalho acredita-se que o desacoplamento
do PC é o que melhor descreve as inovações propostas. Desacoplar o PC leva uma
infinidade de possibilidade para o espaço de usuário uma vez que o processo
pode fazer operações semelhantes ao do escalonador, sem grandes custos e dentro
do mesmo intervalo de execução do processo. O lwC tem como principal
característica um robusto e interessante modelo de programação que permite
aplicações no espaço de usuário utilizarem novos paradigmas de desenvolvimento.
Isso cria diversas oportunidades para criar novos tipos de manipulações, tal
como criar \emph{snapshot} do atual estado do processo e depois reverter o
processo para o estado anterior. Outra possibilidade é mudar para um novo
contexto de processo com acesso restrito para alguma região da memória antes da
execução de um código sensível. Isso não é como utilizar threads ou processos
independentes, mas ao invés de depender do escalonador para mudar o contexto do
processo (que é razoavelmente caro) a própria aplicação por si mesmo pode
escolher quando e qual contexto manipular, assim fornecendo um controle fino
para os programadores (que pode melhorar o desempenho e a segurança). Note que
o escalonador não interfere nesse processo, a troca de contexto no lwC acontece
dentro do intervalo de tempo fornecido para o processo.

Vários dos trabalhos analisados, tem preocupação com o gerenciamento e acesso a
memória; em especial, vários deles questionam o tratamento dado a memória pelos
SOs atuais.  A abordagem de utilizar um único espaço de endereçamento por
processo tem se provado eficiente ao longo dos anos, contudo, apesar do seu
sucesso, essa não é uma abordagem a prova de falhas e ainda precisa receber
melhorias.  Primeiramente, a abordagem de isolar os processos por meio do
espaço de endereçamento linear melhora a confiabilidade do sistema e a
segurança.  Contudo, um processo não tem uma forma de restringir o seu próprio
acesso ao seu segmento de memória que pode ser útil para reduzir os riscos de
falhas de segurança ocasionados por binários de terceiros. Em segundo lugar, o
controle do compartilhamento de memória acontece no tamanho de uma página e
cria a oportunidade para explorar falhas, tais quais \emph{buffer e stack
overflow} ou mesmo o compartilhamento de bibliotecas comprometidas. Os
trabalhos Wedge, shreds e mondrix/mondrian buscam trazer melhorias nessa área.

Observando as abstrações de processos da perspectiva da segurança, o projeto
Wedge retoma uma antiga premissa que defende o princípio do menor privilégio.
Esse justifica que precisamos mudar a lógica atual de dar permissão para tudo,
para uma ideia de negar permissão por padrão. Essa mudança de paradigma torna
possível, supostamente, reduzir as chances de ataques e vazamento de dados uma
vez que o programador precisa indicar explicitamente o que será exposto. Tal
pesquisa, indiretamente propõe o \textbf{desacoplamento dos privilégios} da
abstração de processos . Além disso, ela mantém a compatibilidade entre
aplicações novas e legadas uma vez que é uma opção que o programador pode optar
por usar ou não.

Entrando um pouco mais nas questões de proteção e controle-fino da memória,
destacamos o shreds e o mondrix/mondrian. O shreds nasce com a ideia de evitar
ataques conhecidos como abusos intra-processos de conteúdo da memória.  Os
autores defendem que o acesso a certas regiões da memória do processo
executando em espaço de usuário merecem proteção de acesso. Em tal proposta, os
autores utilizaram um recurso especifico dos processadores ARM em conjunto com
um mecanismo de gerenciamento da região de memória (Seção
\ref{sec:outros_mecanismos_memoria}). Essa proposta entrega mais flexibilidade,
segurança, e controle ao acesso da memória.

Na mesma linha de fornecer controle fino sobre a memoria, os autores do Mondrix
propuseram de forma mais radical um mecanismo de controle do acesso a memória
ao nível das palavras de dados. Para isso, os autores sugeriram alterações no
hardware e do SO de forma a controlar todo acesso com a menor granularidade
possível. Indiretamente, o shreds e o mondrix são propostas de
\textbf{desacoplamento do controle de memória}.

\section{Atomize: Um Modelo Teórico Para a Próxima Geração de Abstrações de Processos}

Este trabalho consiste em analisar os impactos do desacoplamento das abstrações
de processos em SOs modernos e em destacar as características mais relevantes
para a próxima geração de abstrações de processos. Nesse sentido observamos e
analisamos diferentes propostas de desacoplamento que ainda consistem no estado
da arte, acreditando que várias das ideias apresentadas podem atingir o estado
da prática e assim pavimentando novos ramos de pesquisas. Como resultado dessa
pesquisa, compilamos os diversos trabalhos estudados em um modelo que busca
elevar o grau de desacoplamento dentro das abstrações de processos.

Para exemplificar a proposta de desacoplamento deste trabalho, faremos uma
analogia com a evolução do modelo atômico. Começamos por um dos primeiros
modelos atômicos aceito pela comunidade cientifica que foi o modelo proposto
por Dalton, esse afirmava que um atamo era uma esfera maciça e indivisível. Em
seguida, Thomson propôs outro modelo no qual os átomos eram compostos por
partículas positivas e negativas indicando a divisibilidade dos átomos.
Posteriormente, Rutherford refinou o modelo propondo um esquema em que o átomo
possui um núcleo e os elétrons giram em torno desse núcleo formando um sistema
semelhante ao modelo planetário. O modelo atômico continua evoluindo e se
sofisticando cada vez mais, contudo a principal lição que tiramos disso para o
nosso contexto é o constante refinamento do modelo e os avanços que veem junto
com ele.

Seguindo a analogia do modelo atômico, podemos considerar que as abstrações de
processos estão em um estágio equivalente ao modelo de Thomson. A abstração de
processo não é mais um bloco sólido e indivisível, essa possui um leve grau de
desacoplamento uma vez que no passado notou-se a vantagem em se desacoplar o PC
e a Stack possibilitando múltiplos fluxos de execução no mesmo processo
(threads). Seguindo esse raciocínio e buscando avançar o modelo atual,
apresentamos o \textbf{atomize} que consiste em um modelo que busca um elevado
grau de desacoplamento dos elementos da abstração de processos.

Como apresentado na Seção \ref{sec:potenciais}, para que os desacoplamentos
propostos nas pesquisas sejam absorvidos pelos SOs atuais é preciso considerar
diversos aspectos. Em especial destacamos que a as abordagens que seguem uma
implementação leve e que atendem as propostas de desacoplamento destacadas na
Tabela \ref{tab:desacoplamento_beneficio} são preferíveis. A tabela mostra as
propostas de desacoplamento na vertical e os benefícios que essas podem trazer
aos SOs. Por fim, utilizamos uma escala de zero a três \ding{52} que indica o
quanto de benefício um determinado desacoplamento pode levar para uma área.

\input{tables/desacoplar_beneficios}

A Figura \ref{fig:decomposicao_proc} busca mostrar de forma visual o modelo de
abstração de processos proposto por esse trabalho. Na parte central da figura
temos os três elementos fundamentais para o uso dos processos: PC, Stack e IO
context. Nas camadas mais externa temos a VAS, essa é um elemento importante para
que os processos em SOs de proposito geral funcionem de forma apropriada. Em
seguida notamos diversos elementos que orbitam a abstração atual de processos e
que podem ser vistos como elementos menos importantes para o correto
funcionamento da abstração, mas que são fundamentais para a diversas aplicações
modernas.

\begin{figure}[!h]
  \centering
  \includegraphics[width=\textwidth]{decomposicao}
  \caption{Decomposição do processo}
  \label{fig:decomposicao_proc}
\end{figure}

\subsection{A API Atomize}

Em termos de API e implementação, queremos manter os critérios para adoção
descritos na Seção \ref{sec:potenciais} e ao mesmo tempo fornecer uma poderosa
API que possa ser utilizada no espaço de usuário. Para que tal modelo possa ser
implementado é preciso usar uma abordagem que caminha entre uma implementação
estrutural leve e pesada. Implementação pesada, pois será necessário inserir
código intermediários nas atuais abstrações de processo para que esses forneçam
mecanismos externos para que extensões possam atuar sobre a abstração. Note que
tal abordagem visa manter a compatibilidade com as aplicações já existentes
(não queremos forçar mudanças nas aplicações no espaço do usuário).
Implementação leve, pois queremos o maior grau de desacoplamento possível e
também facilitar futuras expansões no modelo.

Como mostrado no Capítulo \ref{cap:trabalhos-analisados}, cada proposta de
extensão na abstração de processo sugere uma API para o seu contexto
específico. Nesse sentido, buscamos aprender as técnicas utilizadas pelos
trabalhos anteriores e combinamos as principais chamadas dentro do atomize. A
seguir apresentamos as operações fornecidas, uma breve descrição sobre o seu
comportamento  e o trabalho na qual foi derivada.  Note que o conjunto dessas
operações pode ser abstraída para uma biblioteca no espaço do usuário e que a
combinação das várias operações possibilita de modelos de programação
(discutiremos padrões de utilização na próxima seção). 

\begin{description}
  \item [\texttt{NEW\_CONTEXT\_INSTANCE}:]

Essa chamada comporta-se de forma similar ao \texttt{fork()}, uma vez que essa
faz uma cópia idêntica dos elementos do processo pai. Essa diferencia-se da
chamada de sistema \texttt{fork()} uma vez que não criar uma nova thread e
compartilhar o mesmo PID do processo pai. Na prática essa função também pode
receber alguns parâmetros que alteram o seu comportamento padrão.

  \begin{itemize}
    \item \textbf{Parâmetros:}

    \item \textbf{Retorno:}

Se estiver no processo que invocou a operação, então um descritor do novo
contexto é retornado. Do contrário, se estiver dentro de um contexto criado,
retorna -1.

    \item \textbf{Referência:}

Chamada baseada no \texttt{lwCreate()} proposto pelo LwC.

  \end{itemize}

  \item [\texttt{CONTEXT\_SWITCH}:]

Essa operação espera um descritor que referencie uma instância de um contexto
que seja válida. Com base no descritor recebido, essa chamada transfere a
thread de execução do processo que invocou tal chamada para a instância de
contexto criada anteriormente.

  \begin{itemize}
    \item \textbf{Parâmetros:}

    \begin{itemize}
      \item \texttt{Descriptor}: Descritor do contexto alvo
    \end{itemize}

    \item \textbf{Retorno:}

Se algo der errado, essa função retorna um valor negativo informando o erro.

    \item \textbf{Referência:}

Chamada baseada no \texttt{lwSwitch()} proposto pelo LwC.

  \end{itemize}

  \item [\texttt{VIRTUALIZATION\_MODE}:]

A chamada para essa operação faz com que o processo entre em modo de
virtualização, i.e., faz uso dos recursos de virtualização disponíveis. Note
que essa função pode ter o seu comportamento alterado via parâmetro ou via
configurações externas. Dentre as possíveis configurações encontra-se a
possibilidade de restringir qual operação de virtualização deseja-se utilizar.

  \begin{itemize}
    \item \textbf{Parâmetros:}

    \begin{itemize}
      \item \texttt{Options}: Recebe opções que restringem o modo de virtualização.
    \end{itemize}

    \item \textbf{Retorno:}

Se algo der errado, essa função retorna um valor negativo informando o erro.

    \item \textbf{Referência:}

Chamada baseada no Dune.

  \end{itemize}

  \item [\texttt{ALLOC\_COMPARTMENT\_MEMORY}:]
  \item [\texttt{FREE\_COMPARTMENT\_MEMORY}:]
  \item [\texttt{REGISTER\_TRANSFER\_CONTROL}:]
  \item [\texttt{REGISTER\_TRANSFER\_ENTRY}:]
  \item [\texttt{ENTER\_COMPARTMENT}:]
  \item [\texttt{EXIT\_COMPARTMENT}:]
  \item [\texttt{NEW\_EXECUTION\_CONTEXT}:]
  \item [\texttt{SET\_GLOBAL\_CONFIG}:]
\end{description}

\subsection{Padrões de Utilização}

\input{algorithm/syscall.tex}
\input{algorithm/snapshot.tex}
